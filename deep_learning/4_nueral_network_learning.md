#   4 신경망 학습

    -  이번 장의 주제는 신경망 학습이다
    - '학습' 이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻한다.
    - 신경망이 학습할 수 있도록 해주는 지표인 손실 함수를 소개한다.
    - 손실함수를 가장 작게 만드는 가중치 매개변수를 찾는 것이 학습의 목표이다.
    - 손실함수를 작게 만드는 기법으로 함수의 기울기를 활용하는 경사법을 소개한다

## 4.1 데이터에서 학습한다.

    - 신경망의 특징은 데이터를 보고 가중치 매개변수를 학습 할수 있다.
    - 가중치 매개변수의 수는 매우 많기 때문에 수작업으로 하는것이 거의 불가능하다.

### 4.1.1 데이터 주도 학습

    - 기계학습의 중심에는 데이터가 존재한다.
    - 이로인해 사람 중심의 접근 방식에서 벗어날수 있다.
    - 사람은 경험을 바탕으로 패턴을 찾는것에 반해 기계는 수집한 데이터로 부터 패턴을 찾으려 한다.
    - 이미지에서 특징을 추출하고 그 특징의 패턴을 기계학습 기술로 학습하는 방법이 있다.
    - 여기서의 특징은 입력 데이터에서 본질적인 데이터(중요한 데이터)를 정확하게 추출할 수 있도록 설계된 변환기를 뜻한다.
    - 이미지의 특징은 보통 벡터로 많이 나타낸다.
    - 컴퓨터 비전 분야에서는 sift surf hog 등의 특징을 많이 사용한다.
    - 이런 이미지 데이터 벡터들을 가지고 대표적인 분류 기법인 svm, knn등으로 학습한다.
    - 데이터에서 규칙을 찾아내는 것은 기계가 하지만 이미지를 벡터로 바꿀때 사용하는 특징은 사람이 설계해야된다.
    - 이 내용들을 그림으로 정리하면 아래와 같다.

![그림 4-2]()

    - 신경망은 이미지를 있는 그대로 학습한다.
    - 두번째 접근 방식(특징과 기계학습 방식)에서는 특징을 사람이 설계했지만 신경망(3번째)은 이미지에 표함된 중요한 특징까지도 기계가 학습한다.
    - 신경망의 이점은 모든 문제를 같은 맥락에서 풀 수 있다는 점이다.

### 4.1.2 훈련 데이터와 시험 데이터

    - 기계학습 문제는 데이터를 훈련 데이터와 시험 데이터로 나눠서 학습이 가능하다.
    - 훈련데이터만을 학습하고 그것을 가지고 시험데이터로 테스트한다.
    - 범용 능력을 기르기 위해 시험데이터를 분리하는 것이다.
    - 학습을 오래 하게 되면 데이터 셋에만 최적화된 오버피팅 상태가 일어난다.

## 4.2 손실함수

    - 신경망 에서는 현재의 상태를 하나의 지표로 표현해 그 지표를 가장 좋게 만드는 매개변수를 탐색한다.
    - 신경망 함수에서 사용하는 지표를 손실함수 loss function 이라고 한다.
    - 임의의 함수를 사용할수 있지만 오차제곱합과 교차 엔트로피 오차를 사용한다.

### 4.2.1 오차제곱합

    - 가장 많이 사용하는 손실함수는 오차제곱합 sum of squares for error 이다.
    - 정답레이블과 추정한 레이블의 차의 곱을 합으로 나타낸 것이다.
    - 한 원소만 1로하고 나머지 원소를 0으로 나타내는 표기법을 원핫 인코딩 이라고 한다,.

### 4.2.2 교차 엔트로피 오차

    - 다른 손실함수로써 교차 엔트로피 오차 cross entropy error도 있다.
    - 정답일때의 추정의 자연로그를 계산하는 식이다.
    - 정답일때 추정은 0에 가까워진다.

[!그림 4-3]()

### 4.2.3 미니배치 학습

    - 기계 학습은 여러 훈련 데이터를 이용해 학습하므로 이 여러 데이터의 손실함수의 값을 찾는다.
    - 손실함수의 값들의 평균으로 나타낼수 있다.
    - 하지만 거대한 데이터 셋 전체를 손실합수로 표현하는것은 비효율 적이다.
    - 따라서 데이터중 일부를 뽑아서 학습을 수행한다 이를 미니 배치 라고 한다.

### 4.2.4 배치용 교차 엔트로피 오차 구현하기

    - 

### 4.2.5 왜 손실함수를 설정하는가?

    - 왜 우리는 정확도라는 지표를 놔두고 손실 함수의 값 이라는 우회적인 방법을 택하는 이유가 뭘까
    - 손실 함수의 값을 가장 작게하는 매개변수의 값을 찾아야 하는데 매개변수의 미분값을 계산하고 그 값을 단서로 매개변수의 값을 서서히 변화 시킨다. 
    - 미분값이 0이면 매개변수의 변화가 없어진다.
    - 정확도를 지표로 삼게되면 매개변수의 미분값이 0으로 되버리는 양이 많아 정확한 탐색이 어렵기 때문이다.
    - 정확도는 매개변수의 조그만 변화에는 거의 변화를 보이지 않고 반응이있더라도 그 값이 불연속 적으로 갑자기 변한다.
    - 이는 계단 함수를 활성화 함수로 사용하지 않는 이유와도 똑같다.(계단 함수의 미분값은 대부분이 0이다.)

## 4.3 수치 미분

    - 경사법에서는 기울기 값을 기준으로 나아갈 방향을 정한다.

### 4.3.1 미분

    - 미분은 좌표 간에 기울기를 구하는 것이다 
    - 진짜 미분은 거의 점위치에서 기울기를 구하지만 프로그램에서는 오차가 발생한다.
    - 컴퓨터에서는 0과 가깝게 구현이 불가능 하기 때문..?
    - 따라서 x 축의 값 2개의 중심을 이용해서 중심 차분 혹은 중앙 차분을 구한다.

### 4.3.2 수치 미분의 예

    - 앞 절의 수치 미분을 사용하여 간단한 함수를 미분해 본다.

### 4.3.3 편미분

    - 변수가 여렷인 함수에 대한 미분을 편미분 이라고 한다.
    - 이 문제들을 변수가 하나인 문제로 만들고 그 변수를 미분한다.

## 4.4 기울기

    - 모든 변수에 대해 편미분 한것을 벡터로 정리한 것을 기울기 라고 한다.
    - 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향이다.

### 4.4.1 경사법(경사 하강법)

    - 



